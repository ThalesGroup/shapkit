---

title: Projected Stochastic Gradient Shapley

keywords: fastai
sidebar: home_sidebar

summary: "Estimate the Shapley Values using a Projected Stochastic Gradient algorithm."
description: "Estimate the Shapley Values using a Projected Stochastic Gradient algorithm."
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/sgd_shapley.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Theory">Theory<a class="anchor-link" href="#Theory"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Shapley-Value-definition">Shapley Value definition<a class="anchor-link" href="#Shapley-Value-definition"> </a></h3><p>In Collaborative Game Theory, Shapley Values ([Shapley,1953]) can distribute a reward among players in a fairly way according to their contribution to the win in a cooperative game. We note $\mathcal{M}$ a set of $d$ players. Moreover, $v : P(\mathcal{M}) \rightarrow R_v$ a reward function such that $v(\emptyset) = 0$. The range $R_v$ can be $\Re$ or a subset of $\Re$. $P(\mathcal{M})$ is a family of sets over $\mathcal{M}$. If $S \subset \mathcal{M}\text{, } v(S)$ is the amount of wealth produced by coalition $S$ when they cooperate.</p>
<p>The Shapley Value of a player $j$ is a fair share of the global wealth $v(\mathcal{M})$ produced by all players together:</p>
<p>{% raw %}
$$\phi_j(\mathcal{M},v) = \sum_{S \subset \mathcal{M}\backslash \{j\}}\frac{(d -|S| - 1)!|S|!}{d!}\left(v(S\cup \{j\}) - v(S)\right),$$
{% endraw %}</p>
<p>with $|S| = \text{cardinal}(S)$, i.e. the number of players in coalition $S$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Shapley-Values-as-contrastive-local-attribute-importance-in-Machine-Learning">Shapley Values as contrastive local attribute importance in Machine Learning<a class="anchor-link" href="#Shapley-Values-as-contrastive-local-attribute-importance-in-Machine-Learning"> </a></h3><p>Let be $X^*\subset\Re^d$ a dataset of individuals where a Machine Learning model $f$ is trained and/or tested and $d$  the dimension of $X^*$. $d&gt;1$ else we do not need to compute Shapley Value. We consider the attribute importance of an individual $\mathbf{x^*} = \{x_1^*, \dots, x_d^*\} \in X^*$ according to a given reference $\mathbf{r} = \{r_1, \dots, r_d\}\in X^*$.  We're looking for $\boldsymbol{\phi}=(\phi_j)_{j\in\{1, \dots, d\}}\in \Re^d$ such that:
$$ \sum_{j=1}^{d} \phi_j = f(\mathbf{x^*}) - f(\mathbf{r}), $$ 
where $\phi_j$ is the attribute contribution of feature indexed $j$.  We loosely identify each feature by its column number. Here the set of players $\mathcal{M}=\{1, \dots, d\}$ is the feature set.</p>
<p>In Machine Learning, a common choice for the reward is $ v(S) = \mathbb{E}[f(X) | X_S = \mathbf{x_S^*}]$, where $\mathbf{x_S^*}=(x_j^*)_{j\in S}$ and $X_S$ the element of $X$ for the coalition $S$. 
For any $S\subset\mathcal{M}$, let's define $ z(\mathbf{x^*},\mathbf{r},S)$ such that $z(\mathbf{x^*},\mathbf{r},\emptyset) = \mathbf{r}$, \ $z(\mathbf{x^*},\mathbf{r},\mathcal{M}) = \mathbf{x^*}$ and</p>
$$ z(\mathbf{x^*},\mathbf{r},S) = (z_1,\dots, z_d) \text{ with } z_i =  x_i^* \text{ if } i \in S \text{ and } r_i  \text{ otherwise }$$<p></p>
<p>As explain in [Merrick,2019], each reference $\textbf{r}$ sets a single-game with $ v(S) = f(z(\mathbf{x^*},\mathbf{r},S)) - f(\mathbf{r}) $, $v(\emptyset) = 0 $ and $v(\mathcal{M}) = f(\mathbf{x^*}) - f(\mathbf{r}) $.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Estimation-of-Shapley-Values-by-a-Projected-Stochastic-Gradient-algorithm.">Estimation of Shapley Values by a Projected Stochastic Gradient algorithm.<a class="anchor-link" href="#Estimation-of-Shapley-Values-by-a-Projected-Stochastic-Gradient-algorithm."> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The Shapley Values are the only solution of a weighted linear regression problem with an equality constraint (see [<a class="latex_cit" id="call-RVZ" href="#cit-RVZ">RVZ</a>], [<a class="latex_cit" id="call-Lundberg" href="#cit-Lundberg">Lundberg</a>] and [<a class="latex_cit" id="call-Aas" href="#cit-Aas">Aas</a>]):</p>
$$ \underset{\boldsymbol{\phi}\in \Re^d}{\text{argmin}} \sum_{S \in \mathcal{M}, S \neq \{\emptyset, \mathcal{M}\}} w_S \ [v(S) - \sum_{j \in S} \phi_j]^2  $$<p></p>
<p>{% raw %}
$$ \text{subject to} \sum_{i=j}^{d} \phi_j = v(\mathcal{M}) $$
{% endraw %}</p>
<p>where the weights $w_S = \dfrac{(d - 1)}{ {d\choose|S|} |S| (d - |S|)}$.</p>
<p>The function we want to minimize is:
{% raw %}
$$ F(\boldsymbol{\phi}) = (X\boldsymbol{\phi} - Y)^T W (X\boldsymbol{\phi} - Y) = \dfrac{1}{n} \sum_{i=1}^{n} n w_i (y_i - \mathbf{x_i}^T \boldsymbol{\phi})^2 = \dfrac{1}{n} \sum_{i=1}^{n} g_i(\boldsymbol{\phi}), $$
{% endraw %}</p>
<p>$F$ is a $\mu$-strongly convex function defined on a convex set:
{% raw %}
$$ K = \{\boldsymbol{\phi}; \sum_{j=1}^{d} \phi_j = v(\mathcal{M}) \ ; \ ||\boldsymbol{\phi}|| \le D \} = K_1 \cap K_2. $$
{% endraw %}</p>
<p>We denote $\boldsymbol{\phi_t}=(\phi_i^t)_{i\in\{1, \dots, d\}}$ the Shapley Values estimator at the iteration $t$. We also define $i_t\sim p$, with $p$ a discrete uniform distribution with support $\{1, \dots, n\}$, the coalition randomly draw for the iteration $t$. To find the unique minimum of $F$ on $K$, the Projected Stochastic gradient algorithm at each iteration $t$ follows the rules:</p>
<p>Sample a coalition:
{% raw %}
$$ i_t \sim p$$
{% endraw %}
One step of gradient descent:
{% raw %}
$$ \boldsymbol{\phi_t} = \text{Proj}_K (\boldsymbol{\phi_{t-1}} - \gamma_t \ (n p_{i_t})^{-1} \nabla g_{i_t}) $$
{% endraw %}
where</p>
<ul>
<li>$\gamma_t$ is a constant or decreasing step-size (also called the learning rate). $\forall t, \gamma_t &gt; 0$;</li>
<li>$\text{Proj}_K$ is the orthogonal projection on $K$;</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="References">References<a class="anchor-link" href="#References"> </a></h3><p>[Shapley,1953] <em>A value for n-person games</em>. Lloyd S Shapley. In Contributions to the Theory of Games, 2.28 (1953), pp. 307 - 317.</p>
<p>[Merrick,2019] <em>The Explanation Game: Explaining Machine Learning Models with Cooperative Game Theory</em>. Luke Merrick, Ankur Taly, 2019.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Function">Function<a class="anchor-link" href="#Function"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Parameters</strong></p>
<ul>
<li><p><code>x</code>: pandas Series. The instance $\mathbf{x^*}$ for which we want to calculate Shapley value of each attribute,</p>
</li>
<li><p><code>fc</code>: python function. The reward function $v$,</p>
</li>
<li><p><code>r</code>: pandas Series. The reference $\mathbf{r}$. The Shapley values (attribute importance) is a contrastive explanation according to this individual,</p>
</li>
<li><p><code>n_iter</code>: integer. The number of iteration,</p>
</li>
<li><p><code>step</code>: float. Step size for the SGD algorithm,</p>
</li>
<li><p><code>step_type</code>: string. Type of step-size learning rule. Options are: "constant", "sqrt", "inverse",</p>
</li>
<li><p><code>callback</code>: optional. An python object which can be called at each iteration to record distance to minimum for example. At each iteration, callback(Φ),</p>
</li>
<li><p><code>Φ_0</code>: numpy array or pandas Series, optional. Initial vector for the SGD algorithm.</p>
</li>
</ul>
<p><strong>Returns</strong></p>
<ul>
<li><code>Φ</code>: pandas Series. Shapley values of each attribute</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="ncr" class="doc_header"><code>ncr</code><a href="https://github.com/sgrah-oss/shapkit/tree/master/shapkit/sgd_shapley.py#L40" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>ncr</code>(<strong><code>n</code></strong>, <strong><code>r</code></strong>)</p>
</blockquote>
<p>Combinatorial computation: number of subsets of size r among n elements
Efficient algorithm</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SGDshapley" class="doc_header"><code>class</code> <code>SGDshapley</code><a href="https://github.com/sgrah-oss/shapkit/tree/master/shapkit/sgd_shapley.py#L51" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SGDshapley</code>(<strong><code>d</code></strong>, <strong><code>C</code></strong>)</p>
</blockquote>
<p>Estimate the Shapley Values using a Projected Stochastic Gradient algorithm.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="SGDshapley.sgd" class="doc_header"><code>SGDshapley.sgd</code><a href="https://github.com/sgrah-oss/shapkit/tree/master/shapkit/sgd_shapley.py#L137" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>SGDshapley.sgd</code>(<strong><code>x</code></strong>, <strong><code>fc</code></strong>, <strong><code>ref</code></strong>, <strong><code>n_iter</code></strong>=<em><code>100</code></em>, <strong><code>step</code></strong>=<em><code>0.1</code></em>, <strong><code>step_type</code></strong>=<em><code>'sqrt'</code></em>, <strong><code>callback</code></strong>=<em><code>None</code></em>, <strong><code>Φ_0</code></strong>=<em><code>False</code></em>)</p>
</blockquote>
<p>Stochastic gradient descent algorithm
The game is defined for an element x, a reference r and function fc</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Example">Example<a class="anchor-link" href="#Example"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We use a simulated dataset from the book <em>Elements of Statistical Learning</em> ([hastie,2009], the Radial example). $X_1, \dots , X_{d}$ are standard independent Gaussian. The model is determined by:</p>
<p>{% raw %}
$$ Y = \prod_{j=1}^{d} \rho(X_j), $$
{% endraw %}</p>
<p>where $\rho\text{: } t \rightarrow \sqrt{(0.5 \pi)} \exp(- t^2 /2)$. The regression function $f_{regr}$ is deterministic and simply defined by $f_r\text{: } \textbf{x} \rightarrow \prod_{j=1}^{d} \phi(x_j)$. For a reference $\mathbf{r^*}$ and a target $\mathbf{x^*}$, we define the reward function $v_r^{\mathbf{r^*}, \mathbf{x^*}}$ such as for each coalition $S$, $v_r^{\mathbf{r^*}, \mathbf{x^*}}(S) = f_{regr}(\mathbf{z}(\mathbf{x^*}, \mathbf{r^*}, S)) - f_{regr}(\mathbf{r^*}).$</p>
<p>[hastie,2009] <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition</em>. Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome. Springer Series in Statistics, 2009.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">d</span><span class="p">,</span> <span class="n">n_samples</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span>
<span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
<span class="n">Sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">d</span><span class="p">,</span><span class="n">d</span><span class="p">))</span>
<span class="n">np</span><span class="o">.</span><span class="n">fill_diagonal</span><span class="p">(</span><span class="n">Sigma</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">d</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">Sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_samples</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">d</span><span class="o">+</span><span class="mi">1</span><span class="p">)])</span>
<span class="k">def</span> <span class="nf">fc</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">phi_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="o">.</span><span class="mi">5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">phi_x</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)):</span>
    <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">fc</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="n">d</span> <span class="o">-</span> <span class="mi">2</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;dimension = </span><span class="si">{0}</span><span class="s2"> ; nb of coalitions = </span><span class="si">{1}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">d</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">n</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>dimension = 5 ; nb of coalitions = 30
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Pick-an-individual-x-to-explain">Pick an individual x to explain<a class="anchor-link" href="#Pick-an-individual-x-to-explain"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">],:]</span>
<span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Single-reference">Single reference<a class="anchor-link" href="#Single-reference"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">reference</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">],:]</span>
<span class="n">reference</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sgd_est</span> <span class="o">=</span> <span class="n">SGDshapley</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="n">sgd_shap</span> <span class="o">=</span> <span class="n">sgd_est</span><span class="o">.</span><span class="n">sgd</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="n">fc</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="n">reference</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">step</span><span class="o">=.</span><span class="mi">1</span><span class="p">,</span> <span class="n">step_type</span><span class="o">=</span><span class="s2">&quot;sqrt&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sgd_shap</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Tests">Tests<a class="anchor-link" href="#Tests"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x_pred</span> <span class="o">=</span> <span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">reference_pred</span> <span class="o">=</span> <span class="n">fc</span><span class="p">(</span><span class="n">reference</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sgd_shap</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="p">(</span><span class="n">x_pred</span> <span class="o">-</span> <span class="n">reference_pred</span><span class="p">))</span> <span class="o">&lt;=</span> <span class="mf">1e-10</span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">true_shap</span> <span class="o">=</span> <span class="n">ShapleyValues</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="n">fc</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="n">reference</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">sgd_shap</span> <span class="o">-</span> <span class="n">true_shap</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mf">0.1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 5/5 [00:00&lt;00:00, 469.61it/s]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

