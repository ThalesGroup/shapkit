---

title: Shapkit

keywords: fastai
sidebar: home_sidebar

summary: "Interpret machine learning predictions using agnostic local feature importance based on Shapley Values. Documentation: https://thalesgroup.github.io/shapkit/"
description: "Interpret machine learning predictions using agnostic local feature importance based on Shapley Values. Documentation: https://thalesgroup.github.io/shapkit/"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/index.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Overview">Overview<a class="anchor-link" href="#Overview"> </a></h2><h3 id="Objective">Objective<a class="anchor-link" href="#Objective"> </a></h3><p>Machine Learning is enjoying an increasing success in many applications: medical, marketing, defense, cyber security, transport. It is becoming a key tool in critical systems. However, models are often very complex and highly non-linear. This is problematic, especially for critical systems, because end-users need to fully understand decisions of an algorithm (e.g. why an alert has been triggered, why a person has a high probability of cancer recurrence,. . . ). One solution is to offer an interpretation for each individual prediction based on attribute relevance. Shapley Values allow to distribute fairly contributions for each attribute in order to understand the difference between a predicted value for an observation and a base value (e.g. the average prediction of a reference population).</p>
<p>The method used is:</p>
<ul>
<li><strong>agnostic</strong>: no particular information on the model is needed, it works with black box algorithms. We only define a reward funtion (e.g. the model output).</li>
<li><strong>local</strong>: the explanation is computed at instance level. Thus, each interpretation is associated to a given prediction.</li>
<li>More suitable for <strong>tabular data</strong> with meaningful features.</li>
</ul>
<h3 id="A-concrete-use-case:-COMPAS">A concrete use case: COMPAS<a class="anchor-link" href="#A-concrete-use-case:-COMPAS"> </a></h3><blockquote><p><em>COMPAS (Correctional Offender Management Profiling for Alternative Sanctions) is a popular commercial algorithm used by judges and parole officers for scoring criminal defendantâ€™s likelihood of reoffending (recidivism)</em></p>
</blockquote>
<p>Assume that we have trained a machine learning model to predict the probability of recividism of a given individual. The algorithm is quite effective but it only returns a probability score without any details on how it has made its choice.
We would like to know how each attribute (characteristic) influences the model output. Furthermore, contributions explain the difference between the individual prediction and the mean prediction for all references. These references are defined by the user (e.g. for classification, interesting references are selected into other predicted classes).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include image.html alt="Exporting from nbdev" caption="On this example, we can analyze that the age (21 years old) and the ethnicity of the individual x increase respectively by 46% and 15% the estimated probability of recidivism. In the meantime, the fact that he has never commited any crimes decreases the probability by 9%." max-width="1000" file="/images/compas_plot.png" %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This picture displays the kind of interpretation associated to a given prediction for individual x. We want to understand the model decision associated to an individual x. As an example, here the individual  has a probability of 70% to reoffend. (the blue tick at top right).
Attribute importance are computed with respect to one or several references. On this example, we chose only non predicted recividists as good elements of comparison. The mean probability for that group of references is about 14% (green tick at the bottom left).
Finally, the gap between our individual prediction and the mean reference prediction is splitted by the attribute importance. The sum of all contributions equals that difference. 
Now, we can analyze that the age (21 years old) and the ethnicity of the individual x increase respectively by 46% and 15% the estimated probability of recidivism. In the meantime, the fact that he has never commited any crimes decreases the probability by 9%.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Install">Install<a class="anchor-link" href="#Install"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

<pre><code>pip install shapkit</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Dependencies">Dependencies<a class="anchor-link" href="#Dependencies"> </a></h2><ul>
<li><a href="https://www.python.org/downloads/">python3</a> (&gt;= 3.6)</li>
<li><a href="https://numpy.org/">numpy</a> (&gt;= 1.17.2)</li>
<li><a href="https://pandas.pydata.org/">pandas</a> (&gt;= 0.25.3)</li>
<li><a href="https://matplotlib.org/">matplotlib</a> (&gt;= 2.2.3)</li>
<li><a href="https://seaborn.pydata.org/">seaborn</a> (&gt;= 0.9.0)</li>
<li><a href="https://github.com/tqdm/tqdm">tqdm</a> [optional] (&gt;= 4.26.0)</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="How-to-use">How to use<a class="anchor-link" href="#How-to-use"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The method is a post-hoc explanation, so you do not have to change your routine. Firstly, train your model:</p>
<div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
<p>Then, define your reward function <code>fc</code> (e.g. simply set by your model output):</p>
<div class="highlight"><pre><span></span><span class="n">fc</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
<p>Select an instance <code>x</code> for which you need more interpretation. Pick also one or several <code>reference(s)</code> (instance or dataset of individuals). 
If the number of features is not too high (said lower than 10), you can compute the exact Shapley Values.</p>
<div class="highlight"><pre><span></span><span class="n">true_shap</span> <span class="o">=</span> <span class="n">ShapleyValues</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="n">fc</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="n">reference</span><span class="p">)</span>
</pre></div>
<p>If the dimension exceeds about 15, then you may need approximation algorithms to estimate the Shapley Values.</p>
<ul>
<li>Monte Carlo algorithm:</li>
</ul>
<div class="highlight"><pre><span></span><span class="n">mc_shap</span> <span class="o">=</span> <span class="n">MonteCarloShapley</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="n">fc</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="n">reference</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
<ul>
<li>Projected Stochastic Gradient Descent algorithm:</li>
</ul>
<div class="highlight"><pre><span></span><span class="n">sgd_est</span> <span class="o">=</span> <span class="n">SGDshapley</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="n">sgd_shap</span> <span class="o">=</span> <span class="n">sgd_est</span><span class="o">.</span><span class="n">sgd</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="n">fc</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="n">reference</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">step</span><span class="o">=.</span><span class="mi">1</span><span class="p">,</span> <span class="n">step_type</span><span class="o">=</span><span class="s2">&quot;sqrt&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Code-and-description">Code and description<a class="anchor-link" href="#Code-and-description"> </a></h2><p>This library is based on <a href="http://nbdev.fast.ai/">nbdev</a>. If you want to modify the lib or run tests, you will have to install it.</p>
<blockquote><p>nbdev is a library that allows you to fully develop a library in Jupyter Notebooks, putting all your code, tests and documentation in one place. That is:you now have a true literate programming environment, as envisioned by Donald Knuth back in 1983!</p>
</blockquote>
<p>Codes, descriptions, small examples and tests are all put together in jupyter notebooks in the folder <code>nbs</code>.</p>
<p>Usefull commands from <code>nbdev</code>:</p>
<ul>
<li>Build your lib by converting all notebooks in folder <code>nbs</code> to .py files
<pre><code>nbdev_build_lib</code></pre>
</li>
</ul>
<ul>
<li>Run all tests in parallel
<pre><code>nbdev_test_nbs</code></pre>
</li>
</ul>
<ul>
<li>Build docs
<pre><code>nbdev_build_docs</code></pre>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Tutorial">Tutorial<a class="anchor-link" href="#Tutorial"> </a></h2><p>Notebook demos are availables in <code>tutorials</code> folder.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="License">License<a class="anchor-link" href="#License"> </a></h2><p>Shapkit is licensed under the terms of the MIT License (see the file LICENSE).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Main-reference">Main reference<a class="anchor-link" href="#Main-reference"> </a></h2><p><em>A Projected SGD algorithm for estimating Shapley Value applied in attribute importance</em>, S. Grah, V. Thouvenot, CD-MAKE 2020</p>

</div>
</div>
</div>
</div>
 

