{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp monte_carlo_shapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Author: Simon Grah <simon.grah@thalesgroup.com>\n",
    "#         Vincent Thouvenot <vincent.thouvenot@thalesgroup.com>\n",
    "\n",
    "# MIT License\n",
    "\n",
    "# Copyright (c) 2020 Thales Six GTS France\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Shapley\n",
    "\n",
    "> Estimate the Shapley Values using an optimized Monte Carlo version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapley Value definition\n",
    "\n",
    "In Collaborative Game Theory, Shapley Values ([Shapley,1953]) can distribute a reward among players in a fairly way according to their contribution to the win in a cooperative game. We note $\\mathcal{M}$ a set of $d$ players. Moreover, $v : P(\\mathcal{M}) \\rightarrow R_v$ a reward function such that $v(\\emptyset) = 0$. The range $R_v$ can be $\\Re$ or a subset of $\\Re$. $P(\\mathcal{M})$ is a family of sets over $\\mathcal{M}$. If $S \\subset \\mathcal{M}\\text{, } v(S)$ is the amount of wealth produced by coalition $S$ when they cooperate.\n",
    "\n",
    "The Shapley Value of a player $j$ is a fair share of the global wealth $v(\\mathcal{M})$ produced by all players together:\n",
    "\n",
    "$$\\phi_j(\\mathcal{M},v) = \\sum_{S \\subset \\mathcal{M}\\backslash \\{j\\}}\\frac{(d -|S| - 1)!|S|!}{d!}\\left(v(S\\cup \\{j\\}) - v(S)\\right),$$\n",
    "\n",
    "with $|S| = \\text{cardinal}(S)$, i.e. the number of players in coalition $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapley Values as contrastive local attribute importance in Machine Learning\n",
    "\n",
    "Let be $X^*\\subset\\Re^d$ a dataset of individuals where a Machine Learning model $f$ is trained and/or tested and $d$  the dimension of $X^*$. $d>1$ else we do not need to compute Shapley Value. We consider the attribute importance of an individual $\\mathbf{x^*} = \\{x_1^*, \\dots, x_d^*\\} \\in X^*$ according to a given reference $\\mathbf{r} = \\{r_1, \\dots, r_d\\}\\in X^*$.  We're looking for $\\boldsymbol{\\phi}=(\\phi_j)_{j\\in\\{1, \\dots, d\\}}\\in \\Re^d$ such that:\n",
    "$$ \\sum_{j=1}^{d} \\phi_j = f(\\mathbf{x^*}) - f(\\mathbf{r}), $$ \n",
    "where $\\phi_j$ is the attribute contribution of feature indexed $j$.  We loosely identify each feature by its column number. Here the set of players $\\mathcal{M}=\\{1, \\dots, d\\}$ is the feature set.\n",
    "\n",
    "In Machine Learning, a common choice for the reward is $ v(S) = \\mathbb{E}[f(X) | X_S = \\mathbf{x_S^*}]$, where $\\mathbf{x_S^*}=(x_j^*)_{j\\in S}$ and $X_S$ the element of $X$ for the coalition $S$. \n",
    "For any $S\\subset\\mathcal{M}$, let's define $ z(\\mathbf{x^*},\\mathbf{r},S)$ such that $z(\\mathbf{x^*},\\mathbf{r},\\emptyset) = \\mathbf{r}$, \\ $z(\\mathbf{x^*},\\mathbf{r},\\mathcal{M}) = \\mathbf{x^*}$ and\n",
    "\n",
    "$$ z(\\mathbf{x^*},\\mathbf{r},S) = (z_1,\\dots, z_d) \\text{ with } z_i =  x_i^* \\text{ if } i \\in S \\text{ and } r_i  \\text{ otherwise }$$ \n",
    "\n",
    "As explain in [Merrick,2019], each reference $\\textbf{r}$ sets a single-game with $ v(S) = f(z(\\mathbf{x^*},\\mathbf{r},S)) - f(\\mathbf{r}) $, $v(\\emptyset) = 0 $ and $v(\\mathcal{M}) = f(\\mathbf{x^*}) - f(\\mathbf{r}) $.\n",
    "\n",
    "Furthermore, we can extend the previous result by using several references well chosen. In that case, the final Shapley Values obtained are simply the average of those calculated on each reference independantly. But, in order to accelerate the estimation, we modify the algorithm to take into account this situation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized Monte Carlo Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inputs:** instance $\\mathbf{x^*}$ and $\\mathbf{r}$, the reward function $v$ and the number of iterations $\\text{T}$.\n",
    "\n",
    "**Result:** the Shapley Values $\\boldsymbol{\\widehat{\\phi}} \\in \\Re^d$.\n",
    "\n",
    "1.&emsp;Initialization: $\\boldsymbol{\\widehat{\\phi}}=  \\{0,\\dots,0\\}$ \\;\n",
    "\n",
    "2.&emsp;For $t=1,\\dots,T$:<br>\n",
    "&emsp;&emsp;(a).&emsp;Choose the subset resulting of an uniform permutation $O\\in\\pi(\\{1, \\dots,d\\})$ of the features values \\;<br>\n",
    "&emsp;&emsp;(b).&emsp;If several references are given, select at random one reference $\\mathbf{r}$ \\;<br>\n",
    "&emsp;&emsp;(c).&emsp; $v^{(1)} = v(\\mathbf{r})$, $\\mathbf{b} = \\mathbf{r}$ \\;<br>\n",
    "&emsp;&emsp;(d).&emsp; For j in $O$:<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;$\\mathbf{b} = x_i^* \\text{ if } i = j \\text{ and } b_i \\text{ otherwise}$, with $i\\in\\{1, \\dots, d\\}$ \\;<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;$ v^{(2)} = v(\\mathbf{b})$ \\;<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;$\\phi_j =  v^{(2)} - v^{(1)}$ \\;<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;Update online $\\widehat{\\phi}$ (if $t > 1$):<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;$\\widehat{\\phi_j} = \\dfrac{t-1}{t} \\widehat{\\phi_j} + \\dfrac{1}{t} \\phi_j$ \\;<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;$v^{(1)} = v^{(2)}$ \\;<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[Shapley,1953] _A value for n-person games_. Lloyd S Shapley. In Contributions to the Theory of Games, 2.28 (1953), pp. 307 - 317.\n",
    "\n",
    "[Merrick,2019] _The Explanation Game: Explaining Machine Learning Models with Cooperative Game Theory_. Luke Merrick, Ankur Taly, 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Parameters__\n",
    "\n",
    "* `x`: pandas Series. The instance $\\mathbf{x^*}$ for which we want to calculate Shapley value of each attribute,\n",
    "\n",
    "* `fc`: python function. The reward function $v$,\n",
    "\n",
    "* `ref`: pandas Series or pandas DataFrame. Either one or several references $\\mathbf{r}$. The Shapley values (attribute importance) is a contrastive explanation according to these individual(s),\n",
    "\n",
    "* `n_iter`: integer. The number of iteration, \n",
    "\n",
    "* `callback`: An python object which can be called at each iteration to record distance to minimum for example. At each iteration, callback(Φ)\n",
    "\n",
    "__Returns__\n",
    "\n",
    "* `Φ`: pandas Series. Shapley values of each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def MonteCarloShapley(x, fc, ref, n_iter, callback=None, seed=0):\n",
    "    \"\"\"\n",
    "    Estimate the Shapley Values using an optimized Monte Carlo version.\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Get general information\n",
    "    feature_names = list(x.index)\n",
    "    d = len(feature_names) # dimension\n",
    "\n",
    "    # Individual reference or dataset of references\n",
    "    if isinstance(ref, pd.core.series.Series):\n",
    "        individual_ref = True\n",
    "        f_r = fc(ref.values)\n",
    "    elif isinstance(ref, pd.core.frame.DataFrame):\n",
    "        if ref.shape[0] == 1:\n",
    "            ref = ref.iloc[0]\n",
    "            individual_ref = True\n",
    "            f_r = fc(ref.values)\n",
    "        else:\n",
    "            individual_ref = False\n",
    "            n_ref = len(ref)\n",
    "\n",
    "    if individual_ref:\n",
    "        # If x[j] = r[j] => Φ[j] = 0 and we can reduce the dimension\n",
    "        distinct_feature_names = list(x[x!=ref].index)\n",
    "        if set(distinct_feature_names) == set(feature_names):\n",
    "            distinct_feature_names = feature_names\n",
    "            sub_d = d\n",
    "            x_cp = x.copy()\n",
    "            r_cp = ref.copy()\n",
    "            reward = lambda z: fc(z)\n",
    "            pass\n",
    "        else:\n",
    "            sub_d = len(distinct_feature_names) # new dimension\n",
    "            x_cp = x[distinct_feature_names].copy()\n",
    "            r_cp = ref[distinct_feature_names].copy()\n",
    "            print(\"new dimension {0}\".format(sub_d))\n",
    "            def reward(z):\n",
    "                z_tmp = ref.copy()\n",
    "                z_tmp[distinct_feature_names] = z\n",
    "                return fc(z_tmp.values)\n",
    "    else:\n",
    "        distinct_feature_names = feature_names\n",
    "        sub_d = d\n",
    "        x_cp = x.copy()\n",
    "        reward = lambda z: fc(z)\n",
    "\n",
    "    # Store all Shapley Values in a numpy array\n",
    "    Φ_storage = np.empty((n_iter, sub_d))\n",
    "\n",
    "    # Monte Carlo loop\n",
    "    for m in tqdm(range(1, n_iter+1)):\n",
    "        # Sample a random permutation order\n",
    "        o = np.random.permutation(sub_d)\n",
    "        # initiate useful variables for this iteration\n",
    "        # if several references select at random one new ref at each iter\n",
    "        if individual_ref:\n",
    "            f_less_j = f_r\n",
    "            x_plus_j = r_cp.values.copy()\n",
    "        else:\n",
    "            r_cp = ref.values[np.random.choice(n_ref, size=1)[0],:].copy()\n",
    "            f_less_j = fc(r_cp)\n",
    "            x_plus_j = r_cp.copy()\n",
    "        # iterate through the permutation of features\n",
    "        for j in o:\n",
    "            x_plus_j[j] = x_cp.values[j]\n",
    "            f_plus_j = reward(x_plus_j)\n",
    "            # update Φ\n",
    "            Φ_j = f_plus_j - f_less_j\n",
    "            Φ_storage[m-1,j] = Φ_j\n",
    "            # reassign f_less_j\n",
    "            f_less_j = f_plus_j\n",
    "        if callback:\n",
    "            Φ = pd.Series(np.mean(Φ_storage[:m,:],axis=0), index=feature_names)\n",
    "            callback(Φ)\n",
    "\n",
    "    Φ_mean = np.mean(Φ_storage,axis=0)\n",
    "    Φ = pd.Series(np.zeros(d), index=feature_names)\n",
    "    Φ[distinct_feature_names] = Φ_mean\n",
    "    return Φ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def MonteCarloShapleyBatch_firstversion(x, fc, ref, n_iter, seed=0):\n",
    "    \"\"\"\n",
    "    Estimate the Shapley Values using an optimized Monte Carlo version in Batch mode.\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Get general information\n",
    "    feature_names = list(x.index)\n",
    "    dimension = len(feature_names)\n",
    "\n",
    "    # Individual reference or dataset of references\n",
    "    if isinstance(ref, pd.core.series.Series):\n",
    "        individual_ref = True\n",
    "    elif isinstance(ref, pd.core.frame.DataFrame):\n",
    "        if ref.shape[0] == 1:\n",
    "            ref = ref.iloc[0]\n",
    "            individual_ref = True\n",
    "        else:\n",
    "            individual_ref = False\n",
    "            n_ref = len(ref)\n",
    "\n",
    "    # Compute the matrix X of hybrid individuals between x and ref\n",
    "    # and keep trace of permutation orders\n",
    "    dtype_features = object if x.dtype == object else float\n",
    "    array_of_hybrid_individuals = np.empty(shape=(n_iter * (dimension+1), dimension), dtype=dtype_features)\n",
    "    orders = np.zeros(shape=(n_iter * (dimension+1),), dtype=np.int32)\n",
    "\n",
    "    for iter_monte_carlo in range(n_iter):\n",
    "        order = np.random.permutation(dimension)\n",
    "        if individual_ref == True:\n",
    "            hybrid_individual = ref.values.copy()\n",
    "        else:\n",
    "            hybrid_individual = ref.values[np.random.choice(n_ref, size=1)[0],:].copy()\n",
    "        array_of_hybrid_individuals[iter_monte_carlo * (dimension+1),:] = hybrid_individual\n",
    "        orders[iter_monte_carlo * (dimension+1)] = -1\n",
    "        for iter_order, idx_feature in enumerate(order):\n",
    "            hybrid_individual[idx_feature] = x.values[idx_feature]\n",
    "            array_of_hybrid_individuals[iter_monte_carlo*(dimension+1) + (iter_order+1),:] = hybrid_individual\n",
    "            orders[iter_monte_carlo*(dimension+1) + (iter_order+1)] = idx_feature\n",
    "\n",
    "    try:\n",
    "        rewards = fc(array_of_hybrid_individuals)\n",
    "    except Exception as e:\n",
    "        print(\"Oops!\", e.__class__, \"occurred.\")\n",
    "        print(\"Your function fc should be able to handle a data set of inputs\")\n",
    "        exit()\n",
    "\n",
    "    rewards_diff = np.diff(rewards)\n",
    "\n",
    "    mc_shap_batch = pd.Series(np.zeros(dimension), index=feature_names)\n",
    "    for idx_feature in range(dimension):\n",
    "        shap_val_feature = np.mean(rewards_diff[orders[1:] == idx_feature])\n",
    "        mc_shap_batch[idx_feature] = shap_val_feature\n",
    "\n",
    "    return mc_shap_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def MonteCarloShapleyBatch(x, fc, ref, n_iter, seed=0):\n",
    "    \"\"\"\n",
    "    Estimate the Shapley Values using an optimized Monte Carlo version in Batch mode.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Get general information\n",
    "    feature_names = list(x.index)\n",
    "    dimension = len(feature_names)\n",
    "    # Individual reference or dataset of references\n",
    "    if isinstance(ref, pd.core.series.Series):\n",
    "        individual_ref = True\n",
    "    elif isinstance(ref, pd.core.frame.DataFrame):\n",
    "        if ref.shape[0] == 1:\n",
    "            ref = ref.iloc[0]\n",
    "            individual_ref = True\n",
    "        else:\n",
    "            individual_ref = False\n",
    "            n_ref = len(ref)\n",
    "    \n",
    "    # Compute the matrix X of hybrid individuals between x and ref\n",
    "    # and keep trace of permutation orders\n",
    "    dtype_features = object if x.dtype == object else float\n",
    "    array_of_hybrid_individuals = []\n",
    "    orders = []\n",
    "    for iter_monte_carlo in range(n_iter):\n",
    "        order = np.random.permutation(dimension)\n",
    "        if individual_ref == True:\n",
    "            hybrid_individual = ref.values.copy()\n",
    "        else:\n",
    "            hybrid_individual = ref.values[np.random.choice(n_ref, size=1)[0],:].copy()\n",
    "        array_of_hybrid_individuals.append(np.copy(hybrid_individual))\n",
    "        orders.append(-1)\n",
    "        for iter_order, idx_feature in enumerate(order):\n",
    "            hybrid_individual[idx_feature] = x.values[idx_feature]\n",
    "            array_of_hybrid_individuals.append(np.copy(hybrid_individual))\n",
    "            orders.append(idx_feature)       \n",
    "    array_of_hybrid_individuals = np.array(array_of_hybrid_individuals)\n",
    "    orders = np.array(orders)\n",
    "    try:\n",
    "        rewards = fc(array_of_hybrid_individuals)\n",
    "    except Exception as e:\n",
    "        print(\"Oops!\", e.__class__, \"occurred.\")\n",
    "        print(\"Your function fc should be able to handle a data set of inputs\")\n",
    "        exit()\n",
    "\n",
    "    rewards_diff = np.diff(rewards)\n",
    "    mc_shap_batch = pd.Series(np.zeros(dimension), index=feature_names)\n",
    "    for idx_feature in range(dimension):\n",
    "        shap_val_feature = np.mean(rewards_diff[orders[1:] == idx_feature])\n",
    "        mc_shap_batch[idx_feature] = shap_val_feature\n",
    "\n",
    "    return mc_shap_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a simulated dataset from the book _Elements of Statistical Learning_ ([hastie,2009], the Radial example). $X_1, \\dots , X_{d}$ are standard independent Gaussian. The model is determined by:\n",
    "\n",
    "$$ Y = \\prod_{j=1}^{d} \\rho(X_j), $$\n",
    "\n",
    "where $\\rho\\text{: } t \\rightarrow \\sqrt{(0.5 \\pi)} \\exp(- t^2 /2)$. The regression function $f_{regr}$ is deterministic and simply defined by $f_r\\text{: } \\textbf{x} \\rightarrow \\prod_{j=1}^{d} \\phi(x_j)$. For a reference $\\mathbf{r^*}$ and a target $\\mathbf{x^*}$, we define the reward function $v_r^{\\mathbf{r^*}, \\mathbf{x^*}}$ such as for each coalition $S$, $v_r^{\\mathbf{r^*}, \\mathbf{x^*}}(S) = f_{regr}(\\mathbf{z}(\\mathbf{x^*}, \\mathbf{r^*}, S)) - f_{regr}(\\mathbf{r^*}).$\n",
    "\n",
    " [hastie,2009] _The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition_. Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome. Springer Series in Statistics, 2009.\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension = 5 ; nb of coalitions = 30\n"
     ]
    }
   ],
   "source": [
    "d, n_samples = 5, 100\n",
    "mu = np.zeros(d)\n",
    "Sigma = np.zeros((d,d))\n",
    "np.fill_diagonal(Sigma, [1] * d)\n",
    "X = np.random.multivariate_normal(mean=mu, cov=Sigma, size=n_samples)\n",
    "X = pd.DataFrame(X, columns=['x'+str(i) for i in range(1, d+1)])\n",
    "def fc(x):\n",
    "    phi_x = np.sqrt(.5 * np.pi) * np.exp(-0.5 * x ** 2)\n",
    "    return np.prod(phi_x)\n",
    "def fc_batch(X):\n",
    "    phi_x = np.sqrt(.5 * np.pi) * np.exp(-0.5 * X ** 2)\n",
    "    return np.prod(phi_x, axis=1)\n",
    "y = fc_batch(X.values)\n",
    "n = 2**d - 2\n",
    "print(\"dimension = {0} ; nb of coalitions = {1}\".format(str(d), str(n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick an individual x to explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1    1.747234\n",
       "x2   -1.410246\n",
       "x3   -0.378242\n",
       "x4   -0.345821\n",
       "x5    0.380062\n",
       "Name: 60, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = X.iloc[np.random.choice(len(X), size=1)[0],:]\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1    0.081577\n",
       "x2   -0.302335\n",
       "x3   -0.726916\n",
       "x4    0.180335\n",
       "x5   -0.520209\n",
       "Name: 94, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference = X.iloc[np.random.choice(len(X), size=1)[0],:]\n",
    "reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 8659.86it/s]\n"
     ]
    }
   ],
   "source": [
    "mc_shap = MonteCarloShapley(x=x, fc=fc, ref=reference, n_iter=10000, callback=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1   -1.162240\n",
       "x2   -0.791358\n",
       "x3    0.192819\n",
       "x4   -0.041533\n",
       "x5    0.062293\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_shap_batch1 = MonteCarloShapleyBatch_firstversion(x=x, fc=fc_batch, ref=reference, n_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1   -1.162240\n",
       "x2   -0.791358\n",
       "x3    0.192819\n",
       "x4   -0.041533\n",
       "x5    0.062293\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_shap_batch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_shap_batch = MonteCarloShapleyBatch(x=x, fc=fc_batch, ref=reference, n_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1   -1.162240\n",
       "x2   -0.791358\n",
       "x3    0.192819\n",
       "x4   -0.041533\n",
       "x5    0.062293\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_shap_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Several references "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.862580</td>\n",
       "      <td>-0.010032</td>\n",
       "      <td>0.050009</td>\n",
       "      <td>0.670216</td>\n",
       "      <td>0.852965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.416232</td>\n",
       "      <td>-0.116747</td>\n",
       "      <td>-1.844788</td>\n",
       "      <td>2.068708</td>\n",
       "      <td>-0.776967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.440167</td>\n",
       "      <td>-0.110557</td>\n",
       "      <td>1.227387</td>\n",
       "      <td>1.920784</td>\n",
       "      <td>0.746433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.081577</td>\n",
       "      <td>-0.302335</td>\n",
       "      <td>-0.726916</td>\n",
       "      <td>0.180335</td>\n",
       "      <td>-0.520209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.824875</td>\n",
       "      <td>-0.997518</td>\n",
       "      <td>0.850591</td>\n",
       "      <td>-0.131578</td>\n",
       "      <td>0.912414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-1.872339</td>\n",
       "      <td>-0.962791</td>\n",
       "      <td>0.080067</td>\n",
       "      <td>0.128726</td>\n",
       "      <td>-0.479120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.007189</td>\n",
       "      <td>-1.296221</td>\n",
       "      <td>0.274992</td>\n",
       "      <td>0.228913</td>\n",
       "      <td>1.352917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.056715</td>\n",
       "      <td>2.300675</td>\n",
       "      <td>0.569497</td>\n",
       "      <td>1.489410</td>\n",
       "      <td>1.264250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-0.105434</td>\n",
       "      <td>0.700428</td>\n",
       "      <td>2.092852</td>\n",
       "      <td>-0.136972</td>\n",
       "      <td>-0.930489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.567455</td>\n",
       "      <td>-0.372642</td>\n",
       "      <td>-0.926557</td>\n",
       "      <td>1.755108</td>\n",
       "      <td>1.209810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x1        x2        x3        x4        x5\n",
       "12  0.862580 -0.010032  0.050009  0.670216  0.852965\n",
       "32 -0.416232 -0.116747 -1.844788  2.068708 -0.776967\n",
       "33  1.440167 -0.110557  1.227387  1.920784  0.746433\n",
       "94  0.081577 -0.302335 -0.726916  0.180335 -0.520209\n",
       "17  1.824875 -0.997518  0.850591 -0.131578  0.912414\n",
       "97 -1.872339 -0.962791  0.080067  0.128726 -0.479120\n",
       "2   1.007189 -1.296221  0.274992  0.228913  1.352917\n",
       "99 -0.056715  2.300675  0.569497  1.489410  1.264250\n",
       "64 -0.105434  0.700428  2.092852 -0.136972 -0.930489\n",
       "36 -0.567455 -0.372642 -0.926557  1.755108  1.209810"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references = X.iloc[np.random.choice(len(X), size=10, replace=False),:]\n",
    "references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:03<00:00, 3251.37it/s]\n"
     ]
    }
   ],
   "source": [
    "mc_shaps = MonteCarloShapley(x=x, fc=fc, ref=references, n_iter=10000, callback=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1   -0.359249\n",
       "x2   -0.243412\n",
       "x3    0.136020\n",
       "x4    0.119385\n",
       "x5    0.108600\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_shaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_shaps_batch1 = MonteCarloShapleyBatch_firstversion(x=x, fc=fc_batch, ref=references, n_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1   -0.359249\n",
       "x2   -0.243412\n",
       "x3    0.136020\n",
       "x4    0.119385\n",
       "x5    0.108600\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_shaps_batch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_shaps_batch = MonteCarloShapleyBatch(x=x, fc=fc_batch, ref=references, n_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1   -0.359249\n",
       "x2   -0.243412\n",
       "x3    0.136020\n",
       "x4    0.119385\n",
       "x5    0.108600\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_shaps_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from shapkit.shapley_values import ShapleyValues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = fc(x.values)\n",
    "reference_pred = fc(reference.values)\n",
    "fcs = []\n",
    "for r in references.values:\n",
    "    fcs.append(fc(r))\n",
    "references_pred = np.mean(fcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.abs(mc_shap.sum() - (x_pred - reference_pred)) <= 1e-10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.abs(mc_shap_batch1.sum() - (x_pred - reference_pred)) <= 1e-10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.abs(mc_shap_batch.sum() - (x_pred - reference_pred)) <= 1e-10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.abs(mc_shaps.sum() - (x_pred - references_pred)) <= 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.abs(mc_shaps_batch1.sum() - (x_pred - references_pred)) <= 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.abs(mc_shaps_batch.sum() - (x_pred - references_pred)) <= 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 240.72it/s]\n"
     ]
    }
   ],
   "source": [
    "true_shap = ShapleyValues(x=x, fc=fc, ref=reference)\n",
    "assert np.linalg.norm(mc_shap - true_shap, 2) <= 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.linalg.norm(mc_shap_batch - true_shap, 2) <= 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 48.49it/s]\n"
     ]
    }
   ],
   "source": [
    "true_shaps = ShapleyValues(x=x, fc=fc, ref=references)\n",
    "assert np.linalg.norm(mc_shaps - true_shaps, 2) <= 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007806901849042836"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(mc_shaps - true_shaps, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.linalg.norm(mc_shaps_batch1 - true_shaps, 2) <= 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.linalg.norm(mc_shaps_batch - true_shaps, 2) <= 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted index.ipynb.\n",
      "Converted inspector.ipynb.\n",
      "Converted monte_carlo_shapley.ipynb.\n",
      "Converted plots.ipynb.\n",
      "Converted sgd_shapley.ipynb.\n",
      "Converted shapley_values.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('env': venv)",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
